{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## WideNet prototype"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[i] Loaded Parameters:\n",
      " 40000 35 0.2 200 \n",
      " dataset/glove/glove.twitter.27B.200d.txt\n",
      "[i] Importing Modules...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/h5py/__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n",
      "Using TensorFlow backend.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[+] Using Keras version 2.1.4\n",
      "[i] Finished Importing Modules\n",
      "[i] . Reading from csv file...Done!\n",
      "[i] Found 30447 unique tokens.\n",
      "[+] Shape of data tensor: (40000, 30)\n",
      "[+] Shape of label tensor: (40000, 4)\n",
      "[+] Number of entries in each category:\n",
      "[+] Training:\n",
      " [ 7697. 10911. 12259.  1133.]\n",
      "[+] Validation:\n",
      " [1947. 2713. 3040.  300.]\n",
      "[i] Loading GloVe from: dataset/glove/glove.twitter.27B.200d.txt ...Done.\n",
      "[+] Proceeding with Embedding Matrix...Completed!\n",
      "Finished running setup.\n"
     ]
    }
   ],
   "source": [
    "%run Setup.ipynb\n",
    "%run ExtraFunctions.ipynb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "embedding_layer = Embedding(len(word_index) + 1,\n",
    "                            EMBEDDING_DIM,\n",
    "                            weights=[embedding_matrix],\n",
    "                            input_length=MAX_SEQUENCE_LENGTH,\n",
    "                            trainable=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Feed the input vector into the embedding layer, then feed the resulting sequence into a bidirectional LSTM layer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "sequence_input = Input(shape=(MAX_SEQUENCE_LENGTH,), dtype='int32')\n",
    "embedded_sequences = embedding_layer(sequence_input)\n",
    "l_lstm1 = Bidirectional(LSTM(4,dropout=0.2,recurrent_dropout=0.2,return_sequences=True))(embedded_sequences)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "inception = [] # append our layers in parallel\n",
    "\n",
    "# kernel 7: best accuracy, some over fitting!\n",
    "l_conv_7 = Conv1D(filters=10,kernel_size=7,activation='relu',kernel_regularizer=regularizers.l2(0.02))(l_lstm1)\n",
    "# kernel 2: good accuracy\n",
    "l_conv_2 = Conv1D(filters=10,kernel_size=2,activation='relu',kernel_regularizer=regularizers.l2(0.01))(l_lstm1)\n",
    "# kernel 6: good accuracy\n",
    "l_conv_6 = Conv1D(filters=10,kernel_size=6,activation='relu',kernel_regularizer=regularizers.l2(0.01))(l_lstm1)\n",
    "# kernel 3: good accuracy, no over fitting\n",
    "l_conv_3 = Conv1D(filters=10,kernel_size=3,activation='relu')(l_lstm1)\n",
    "\n",
    "inception.append(l_conv_7)\n",
    "inception.append(l_conv_2)\n",
    "inception.append(l_conv_6)\n",
    "inception.append(l_conv_3)\n",
    "\n",
    "# poorer performing layers\n",
    "l_conv_4 = Conv1D(filters=10,kernel_size=4,activation='relu',kernel_regularizer=regularizers.l2(0.01))(l_lstm1)\n",
    "l_drop_4 = Dropout(0.4)(l_conv_4)\n",
    "l_conv_5 = Conv1D(filters=10,kernel_size=5,activation='relu',kernel_regularizer=regularizers.l2(0.02))(l_lstm1)\n",
    "l_drop_5 = Dropout(0.4)(l_conv_5)\n",
    "l_conv_8 = Conv1D(filters=10,kernel_size=8,activation='relu',kernel_regularizer=regularizers.l2(0.02))(l_lstm1)\n",
    "l_drop_8 = Dropout(0.4)(l_conv_8)\n",
    "\n",
    "inception.append(l_drop_4)\n",
    "inception.append(l_drop_5)\n",
    "inception.append(l_drop_8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# last parallel layer in inception: max-pooling layer\n",
    "l_pool_i1 = MaxPooling1D(3)(l_lstm1)\n",
    "l_conv_1 = Conv1D(filters=10,kernel_size=1,\n",
    "                    activation='relu',kernel_regularizer=regularizers.l2(0.02))(l_pool_i1)\n",
    "inception.append(l_conv_1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "l_merge = Concatenate(axis=1)(inception)\n",
    "l_pool = MaxPooling1D(4)(l_merge)\n",
    "l_drop = Dropout(0.3)(l_pool)\n",
    "l_flat = Flatten()(l_drop)\n",
    "l_dense = Dense(16, activation='relu',kernel_regularizer=regularizers.l2(0.01))(l_flat)\n",
    "preds = Dense(4, activation='softmax')(l_dense)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Model(sequence_input, preds)\n",
    "adadelta = optimizers.Adadelta(lr=1.0, rho=0.95, epsilon=None, decay=0.0)\n",
    "lr_metric = get_lr_metric(adadelta)\n",
    "model.compile(loss='categorical_crossentropy',\n",
    "              optimizer=adadelta,\n",
    "              metrics=['acc', lr_metric])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "tensorboard = callbacks.TensorBoard(log_dir='./logs', histogram_freq=0, batch_size=16, write_grads=True , write_graph=True)\n",
    "model_checkpoints = callbacks.ModelCheckpoint(\"checkpoint.h5\", monitor='val_loss', verbose=0, save_best_only=True, save_weights_only=False, mode='auto', period=1)\n",
    "lr_schedule = callbacks.LearningRateScheduler(initial_boost)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_1 (InputLayer)            (None, 30)           0                                            \n",
      "__________________________________________________________________________________________________\n",
      "embedding_1 (Embedding)         (None, 30, 200)      6089600     input_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "bidirectional_1 (Bidirectional) (None, 30, 8)        6560        embedding_1[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_5 (Conv1D)               (None, 27, 10)       330         bidirectional_1[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_6 (Conv1D)               (None, 26, 10)       410         bidirectional_1[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_7 (Conv1D)               (None, 23, 10)       650         bidirectional_1[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling1d_1 (MaxPooling1D)  (None, 10, 8)        0           bidirectional_1[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_1 (Conv1D)               (None, 24, 10)       570         bidirectional_1[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_2 (Conv1D)               (None, 29, 10)       170         bidirectional_1[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_3 (Conv1D)               (None, 25, 10)       490         bidirectional_1[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_4 (Conv1D)               (None, 28, 10)       250         bidirectional_1[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "dropout_1 (Dropout)             (None, 27, 10)       0           conv1d_5[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "dropout_2 (Dropout)             (None, 26, 10)       0           conv1d_6[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "dropout_3 (Dropout)             (None, 23, 10)       0           conv1d_7[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_8 (Conv1D)               (None, 10, 10)       90          max_pooling1d_1[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_1 (Concatenate)     (None, 192, 10)      0           conv1d_1[0][0]                   \n",
      "                                                                 conv1d_2[0][0]                   \n",
      "                                                                 conv1d_3[0][0]                   \n",
      "                                                                 conv1d_4[0][0]                   \n",
      "                                                                 dropout_1[0][0]                  \n",
      "                                                                 dropout_2[0][0]                  \n",
      "                                                                 dropout_3[0][0]                  \n",
      "                                                                 conv1d_8[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling1d_2 (MaxPooling1D)  (None, 48, 10)       0           concatenate_1[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "dropout_4 (Dropout)             (None, 48, 10)       0           max_pooling1d_2[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "flatten_1 (Flatten)             (None, 480)          0           dropout_4[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dense_1 (Dense)                 (None, 16)           7696        flatten_1[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dense_2 (Dense)                 (None, 4)            68          dense_1[0][0]                    \n",
      "==================================================================================================\n",
      "Total params: 6,106,884\n",
      "Trainable params: 17,284\n",
      "Non-trainable params: 6,089,600\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()\n",
    "model.save('WideNet.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Progress:\n",
      "Train on 32000 samples, validate on 8000 samples\n",
      "Epoch 1/200\n",
      "32000/32000 [==============================] - 22s 691us/step - loss: 1.1645 - acc: 0.4879 - lr: 6.0000 - val_loss: 1.0546 - val_acc: 0.5636 - val_lr: 6.0000\n",
      "Epoch 2/200\n",
      "32000/32000 [==============================] - 21s 669us/step - loss: 1.0235 - acc: 0.5697 - lr: 1.0000 - val_loss: 1.0197 - val_acc: 0.5735 - val_lr: 1.0000\n",
      "Epoch 3/200\n",
      "32000/32000 [==============================] - 22s 685us/step - loss: 1.0084 - acc: 0.5754 - lr: 1.0000 - val_loss: 1.0136 - val_acc: 0.5745 - val_lr: 1.0000\n",
      "Epoch 4/200\n",
      "32000/32000 [==============================] - 23s 720us/step - loss: 1.0040 - acc: 0.5767 - lr: 1.0000 - val_loss: 1.0155 - val_acc: 0.5729 - val_lr: 1.0000\n",
      "Epoch 5/200\n",
      "32000/32000 [==============================] - 22s 698us/step - loss: 0.9986 - acc: 0.5807 - lr: 1.0000 - val_loss: 1.0110 - val_acc: 0.5754 - val_lr: 1.0000\n",
      "Epoch 6/200\n",
      "32000/32000 [==============================] - 23s 726us/step - loss: 0.9947 - acc: 0.5829 - lr: 1.0000 - val_loss: 1.0070 - val_acc: 0.5770 - val_lr: 1.0000\n",
      "Epoch 7/200\n",
      "32000/32000 [==============================] - 23s 722us/step - loss: 0.9906 - acc: 0.5833 - lr: 1.0000 - val_loss: 1.0098 - val_acc: 0.5761 - val_lr: 1.0000\n",
      "Epoch 8/200\n",
      "32000/32000 [==============================] - 24s 745us/step - loss: 0.9877 - acc: 0.5863 - lr: 1.0000 - val_loss: 1.0118 - val_acc: 0.5746 - val_lr: 1.0000\n",
      "Epoch 9/200\n",
      "32000/32000 [==============================] - 24s 755us/step - loss: 0.9840 - acc: 0.5882 - lr: 1.0000 - val_loss: 1.0052 - val_acc: 0.5791 - val_lr: 1.0000\n",
      "Epoch 10/200\n",
      "32000/32000 [==============================] - 23s 732us/step - loss: 0.9820 - acc: 0.5879 - lr: 1.0000 - val_loss: 1.0031 - val_acc: 0.5803 - val_lr: 1.0000\n",
      "Epoch 11/200\n",
      "32000/32000 [==============================] - 24s 739us/step - loss: 0.9798 - acc: 0.5923 - lr: 1.0000 - val_loss: 1.0010 - val_acc: 0.5790 - val_lr: 1.0000\n",
      "Epoch 12/200\n",
      "32000/32000 [==============================] - 24s 741us/step - loss: 0.9760 - acc: 0.5901 - lr: 1.0000 - val_loss: 1.0001 - val_acc: 0.5804 - val_lr: 1.0000\n",
      "Epoch 13/200\n",
      "32000/32000 [==============================] - 24s 743us/step - loss: 0.9763 - acc: 0.5908 - lr: 1.0000 - val_loss: 1.0027 - val_acc: 0.5789 - val_lr: 1.0000\n",
      "Epoch 14/200\n",
      "32000/32000 [==============================] - 23s 715us/step - loss: 0.9732 - acc: 0.5919 - lr: 1.0000 - val_loss: 0.9988 - val_acc: 0.5798 - val_lr: 1.0000\n",
      "Epoch 15/200\n",
      "32000/32000 [==============================] - 22s 699us/step - loss: 0.9710 - acc: 0.5955 - lr: 1.0000 - val_loss: 0.9979 - val_acc: 0.5816 - val_lr: 1.0000\n",
      "Epoch 16/200\n",
      "32000/32000 [==============================] - 22s 700us/step - loss: 0.9693 - acc: 0.5943 - lr: 1.0000 - val_loss: 0.9999 - val_acc: 0.5799 - val_lr: 1.0000\n",
      "Epoch 17/200\n",
      "32000/32000 [==============================] - 23s 712us/step - loss: 0.9680 - acc: 0.5958 - lr: 1.0000 - val_loss: 0.9950 - val_acc: 0.5820 - val_lr: 1.0000\n",
      "Epoch 18/200\n",
      "32000/32000 [==============================] - 22s 677us/step - loss: 0.9666 - acc: 0.5963 - lr: 1.0000 - val_loss: 0.9958 - val_acc: 0.5816 - val_lr: 1.0000\n",
      "Epoch 19/200\n",
      "32000/32000 [==============================] - 24s 760us/step - loss: 0.9659 - acc: 0.5948 - lr: 1.0000 - val_loss: 0.9955 - val_acc: 0.5798 - val_lr: 1.0000\n",
      "Epoch 20/200\n",
      "32000/32000 [==============================] - 24s 749us/step - loss: 0.9626 - acc: 0.5965 - lr: 1.0000 - val_loss: 0.9956 - val_acc: 0.5790 - val_lr: 1.0000\n",
      "Epoch 21/200\n",
      "32000/32000 [==============================] - 24s 739us/step - loss: 0.9613 - acc: 0.5979 - lr: 1.0000 - val_loss: 0.9926 - val_acc: 0.5809 - val_lr: 1.0000\n",
      "Epoch 22/200\n",
      "32000/32000 [==============================] - 22s 673us/step - loss: 0.9596 - acc: 0.5981 - lr: 1.0000 - val_loss: 0.9915 - val_acc: 0.5810 - val_lr: 1.0000\n",
      "Epoch 23/200\n",
      "32000/32000 [==============================] - 22s 684us/step - loss: 0.9588 - acc: 0.6005 - lr: 1.0000 - val_loss: 0.9942 - val_acc: 0.5829 - val_lr: 1.0000\n",
      "Epoch 24/200\n",
      "32000/32000 [==============================] - 22s 684us/step - loss: 0.9552 - acc: 0.6013 - lr: 1.0000 - val_loss: 0.9940 - val_acc: 0.5805 - val_lr: 1.0000\n",
      "Epoch 25/200\n",
      "32000/32000 [==============================] - 23s 728us/step - loss: 0.9541 - acc: 0.6021 - lr: 1.0000 - val_loss: 0.9919 - val_acc: 0.5811 - val_lr: 1.0000\n",
      "Epoch 26/200\n",
      "32000/32000 [==============================] - 22s 694us/step - loss: 0.9556 - acc: 0.6014 - lr: 1.0000 - val_loss: 0.9932 - val_acc: 0.5791 - val_lr: 1.0000\n",
      "Epoch 27/200\n",
      "32000/32000 [==============================] - 22s 681us/step - loss: 0.9528 - acc: 0.6022 - lr: 1.0000 - val_loss: 0.9941 - val_acc: 0.5830 - val_lr: 1.0000\n",
      "Epoch 28/200\n",
      "32000/32000 [==============================] - 23s 734us/step - loss: 0.9520 - acc: 0.6003 - lr: 1.0000 - val_loss: 0.9844 - val_acc: 0.5820 - val_lr: 1.0000\n",
      "Epoch 29/200\n",
      "32000/32000 [==============================] - 26s 799us/step - loss: 0.9516 - acc: 0.6020 - lr: 1.0000 - val_loss: 0.9898 - val_acc: 0.5791 - val_lr: 1.0000\n",
      "Epoch 30/200\n",
      "32000/32000 [==============================] - 23s 706us/step - loss: 0.9529 - acc: 0.6003 - lr: 1.0000 - val_loss: 0.9864 - val_acc: 0.5814 - val_lr: 1.0000\n",
      "Epoch 31/200\n",
      "32000/32000 [==============================] - 23s 721us/step - loss: 0.9477 - acc: 0.6034 - lr: 1.0000 - val_loss: 0.9872 - val_acc: 0.5801 - val_lr: 1.0000\n",
      "Epoch 32/200\n",
      "32000/32000 [==============================] - 22s 695us/step - loss: 0.9501 - acc: 0.6028 - lr: 1.0000 - val_loss: 0.9884 - val_acc: 0.5825 - val_lr: 1.0000\n",
      "Epoch 33/200\n",
      "32000/32000 [==============================] - 24s 735us/step - loss: 0.9489 - acc: 0.6043 - lr: 1.0000 - val_loss: 0.9914 - val_acc: 0.5798 - val_lr: 1.0000\n",
      "Epoch 34/200\n",
      "26700/32000 [========================>.....] - ETA: 3s - loss: 0.9446 - acc: 0.6046 - lr: 1.0000"
     ]
    }
   ],
   "source": [
    "print(\"Training Progress:\")\n",
    "model_log = model.fit(x_train, y_train, validation_data=(x_val, y_val),\n",
    "          epochs=200, batch_size=50,\n",
    "          callbacks=[tensorboard, lr_schedule])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "model.save('WideNet.h5')\n",
    "pd.DataFrame(model_log.history).to_csv(\"history-inception.csv\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
