{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## LSTM-CNN Filter Experiment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[i] Loaded Parameters:\n",
      " 40000 35 0.2 200 \n",
      " dataset/glove/glove.twitter.27B.200d.txt\n",
      "[i] Importing Modules...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.5/dist-packages/h5py/__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n",
      "Using TensorFlow backend.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[+] Using Keras version 2.1.4\n",
      "[i] Finished Importing Modules\n",
      "[i] . Reading from csv file...Done!\n",
      "[i] Found 30447 unique tokens.\n",
      "[+] Shape of data tensor: (40000, 30)\n",
      "[+] Shape of label tensor: (40000, 4)\n",
      "[+] Number of entries in each category:\n",
      "[+] Training:\n",
      " [ 7739. 10889. 12242.  1130.]\n",
      "[+] Validation:\n",
      " [1905. 2735. 3057.  303.]\n",
      "[i] Loading GloVe from: dataset/glove/glove.twitter.27B.200d.txt ...Done.\n",
      "[+] Proceeding with Embedding Matrix...Completed!\n",
      "Finished running setup.\n"
     ]
    }
   ],
   "source": [
    "%run Setup.ipynb\n",
    "%run ExtraFunctions.ipynb"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load embedding matrix into an `Embedding` layer. Toggle `trainable=False` to prevent the weights from being updated during training."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "embedding_layer = Embedding(len(word_index) + 1,\n",
    "                            EMBEDDING_DIM,\n",
    "                            weights=[embedding_matrix],\n",
    "                            input_length=MAX_SEQUENCE_LENGTH,\n",
    "                            trainable=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### RNN Structure\n",
    "[Reference](https://github.com/richliao/textClassifier), [LTSM](http://colah.github.io/posts/2015-08-Understanding-LSTMs/)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "sequence_input = Input(shape=(MAX_SEQUENCE_LENGTH,), dtype='int32')\n",
    "embedded_sequences = embedding_layer(sequence_input)\n",
    "l_lstm1 = Bidirectional(LSTM(4,dropout=0.2,recurrent_dropout=0.2,return_sequences=True))(embedded_sequences)\n",
    "l_cov1= Conv1D(24, 4, activation='relu')(l_lstm1)\n",
    "l_pool1 = MaxPooling1D(2)(l_cov1)\n",
    "l_drop1 = Dropout(0.3)(l_pool1)\n",
    "l_flat = Flatten()(l_drop1)\n",
    "l_dense = Dense(16, activation='relu')(l_flat)\n",
    "preds = Dense(4, activation='softmax')(l_dense)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "model = Model(sequence_input, preds)\n",
    "adadelta = optimizers.Adadelta(lr=1.0, rho=0.95, epsilon=None, decay=0.0)\n",
    "lr_metric = get_lr_metric(adadelta)\n",
    "model.compile(loss='categorical_crossentropy',\n",
    "              optimizer=adadelta,\n",
    "              metrics=['acc'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "tensorboard = callbacks.TensorBoard(log_dir='./logs', histogram_freq=0, batch_size=16, write_grads=True , write_graph=True)\n",
    "model_checkpoints = callbacks.ModelCheckpoint(\"checkpoint.h5\", monitor='val_loss', verbose=0, save_best_only=True, save_weights_only=False, mode='auto', period=1)\n",
    "lr_schedule = callbacks.LearningRateScheduler(initial_boost)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_1 (InputLayer)         (None, 30)                0         \n",
      "_________________________________________________________________\n",
      "embedding_1 (Embedding)      (None, 30, 200)           6089600   \n",
      "_________________________________________________________________\n",
      "bidirectional_1 (Bidirection (None, 30, 8)             6560      \n",
      "_________________________________________________________________\n",
      "conv1d_1 (Conv1D)            (None, 27, 24)            792       \n",
      "_________________________________________________________________\n",
      "max_pooling1d_1 (MaxPooling1 (None, 13, 24)            0         \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 13, 24)            0         \n",
      "_________________________________________________________________\n",
      "flatten_1 (Flatten)          (None, 312)               0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 16)                5008      \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 4)                 68        \n",
      "=================================================================\n",
      "Total params: 6,102,028\n",
      "Trainable params: 12,428\n",
      "Non-trainable params: 6,089,600\n",
      "_________________________________________________________________\n",
      "Training Progress:\n",
      "Train on 32000 samples, validate on 8000 samples\n",
      "Epoch 1/50\n",
      "32000/32000 [==============================] - 22s 701us/step - loss: 1.1297 - acc: 0.4618 - val_loss: 1.0423 - val_acc: 0.5477\n",
      "Epoch 2/50\n",
      "32000/32000 [==============================] - 22s 675us/step - loss: 1.0124 - acc: 0.5681 - val_loss: 1.0079 - val_acc: 0.5694\n",
      "Epoch 3/50\n",
      "32000/32000 [==============================] - 22s 700us/step - loss: 0.9987 - acc: 0.5713 - val_loss: 0.9994 - val_acc: 0.5741\n",
      "Epoch 4/50\n",
      "32000/32000 [==============================] - 22s 681us/step - loss: 0.9908 - acc: 0.5743 - val_loss: 0.9982 - val_acc: 0.5734\n",
      "Epoch 5/50\n",
      "32000/32000 [==============================] - 21s 671us/step - loss: 0.9814 - acc: 0.5837 - val_loss: 0.9915 - val_acc: 0.5756\n",
      "Epoch 6/50\n",
      "32000/32000 [==============================] - 23s 704us/step - loss: 0.9779 - acc: 0.5810 - val_loss: 0.9873 - val_acc: 0.5815\n",
      "Epoch 7/50\n",
      "32000/32000 [==============================] - 21s 672us/step - loss: 0.9724 - acc: 0.5857 - val_loss: 0.9865 - val_acc: 0.5787\n",
      "Epoch 8/50\n",
      "32000/32000 [==============================] - 21s 672us/step - loss: 0.9683 - acc: 0.5877 - val_loss: 0.9864 - val_acc: 0.5791\n",
      "Epoch 9/50\n",
      "32000/32000 [==============================] - 22s 672us/step - loss: 0.9631 - acc: 0.5903 - val_loss: 0.9841 - val_acc: 0.5799\n",
      "Epoch 10/50\n",
      "32000/32000 [==============================] - 21s 671us/step - loss: 0.9601 - acc: 0.5903 - val_loss: 0.9817 - val_acc: 0.5807\n",
      "Epoch 11/50\n",
      "32000/32000 [==============================] - 22s 675us/step - loss: 0.9553 - acc: 0.5917 - val_loss: 0.9819 - val_acc: 0.5826\n",
      "Epoch 12/50\n",
      "32000/32000 [==============================] - 22s 672us/step - loss: 0.9530 - acc: 0.5935 - val_loss: 0.9792 - val_acc: 0.5834\n",
      "Epoch 13/50\n",
      "32000/32000 [==============================] - 21s 672us/step - loss: 0.9498 - acc: 0.5920 - val_loss: 0.9814 - val_acc: 0.5814\n",
      "Epoch 14/50\n",
      "32000/32000 [==============================] - 23s 704us/step - loss: 0.9481 - acc: 0.5964 - val_loss: 0.9796 - val_acc: 0.5827\n",
      "Epoch 15/50\n",
      "32000/32000 [==============================] - 22s 672us/step - loss: 0.9440 - acc: 0.5993 - val_loss: 0.9779 - val_acc: 0.5846\n",
      "Epoch 16/50\n",
      "32000/32000 [==============================] - 22s 672us/step - loss: 0.9436 - acc: 0.5963 - val_loss: 0.9819 - val_acc: 0.5856\n",
      "Epoch 17/50\n",
      "32000/32000 [==============================] - 22s 677us/step - loss: 0.9424 - acc: 0.5977 - val_loss: 0.9775 - val_acc: 0.5847\n",
      "Epoch 18/50\n",
      "32000/32000 [==============================] - 22s 675us/step - loss: 0.9403 - acc: 0.6009 - val_loss: 0.9792 - val_acc: 0.5825\n",
      "Epoch 19/50\n",
      "32000/32000 [==============================] - 22s 674us/step - loss: 0.9380 - acc: 0.5998 - val_loss: 0.9846 - val_acc: 0.5775\n",
      "Epoch 20/50\n",
      "32000/32000 [==============================] - 22s 675us/step - loss: 0.9347 - acc: 0.6032 - val_loss: 0.9876 - val_acc: 0.5813\n",
      "Epoch 21/50\n",
      "32000/32000 [==============================] - 22s 676us/step - loss: 0.9343 - acc: 0.6026 - val_loss: 0.9798 - val_acc: 0.5806\n",
      "Epoch 22/50\n",
      "32000/32000 [==============================] - 22s 680us/step - loss: 0.9322 - acc: 0.6029 - val_loss: 0.9787 - val_acc: 0.5815\n",
      "Epoch 23/50\n",
      "32000/32000 [==============================] - 22s 675us/step - loss: 0.9313 - acc: 0.6036 - val_loss: 0.9808 - val_acc: 0.5799\n",
      "Epoch 24/50\n",
      "32000/32000 [==============================] - 22s 674us/step - loss: 0.9292 - acc: 0.6018 - val_loss: 0.9807 - val_acc: 0.5839\n",
      "Epoch 25/50\n",
      "32000/32000 [==============================] - 22s 674us/step - loss: 0.9287 - acc: 0.6063 - val_loss: 0.9831 - val_acc: 0.5824\n",
      "Epoch 26/50\n",
      "32000/32000 [==============================] - 22s 674us/step - loss: 0.9262 - acc: 0.6062 - val_loss: 0.9828 - val_acc: 0.5805\n",
      "Epoch 27/50\n",
      "32000/32000 [==============================] - 22s 675us/step - loss: 0.9278 - acc: 0.6050 - val_loss: 0.9895 - val_acc: 0.5786\n",
      "Epoch 28/50\n",
      "32000/32000 [==============================] - 22s 676us/step - loss: 0.9262 - acc: 0.6092 - val_loss: 0.9836 - val_acc: 0.5803\n",
      "Epoch 29/50\n",
      "32000/32000 [==============================] - 22s 674us/step - loss: 0.9256 - acc: 0.6050 - val_loss: 0.9860 - val_acc: 0.5827\n",
      "Epoch 30/50\n",
      "32000/32000 [==============================] - 22s 676us/step - loss: 0.9246 - acc: 0.6089 - val_loss: 0.9805 - val_acc: 0.5823\n",
      "Epoch 31/50\n",
      "32000/32000 [==============================] - 22s 676us/step - loss: 0.9238 - acc: 0.6084 - val_loss: 0.9808 - val_acc: 0.5836\n",
      "Epoch 32/50\n",
      "32000/32000 [==============================] - 22s 675us/step - loss: 0.9220 - acc: 0.6078 - val_loss: 0.9791 - val_acc: 0.5835\n",
      "Epoch 33/50\n",
      "32000/32000 [==============================] - 22s 674us/step - loss: 0.9217 - acc: 0.6102 - val_loss: 0.9861 - val_acc: 0.5771\n",
      "Epoch 34/50\n",
      "32000/32000 [==============================] - 22s 681us/step - loss: 0.9209 - acc: 0.6115 - val_loss: 0.9787 - val_acc: 0.5815\n",
      "Epoch 35/50\n",
      "32000/32000 [==============================] - 22s 675us/step - loss: 0.9191 - acc: 0.6127 - val_loss: 0.9855 - val_acc: 0.5807\n",
      "Epoch 36/50\n",
      "32000/32000 [==============================] - 22s 675us/step - loss: 0.9176 - acc: 0.6122 - val_loss: 0.9877 - val_acc: 0.5829\n",
      "Epoch 37/50\n",
      "32000/32000 [==============================] - 22s 674us/step - loss: 0.9186 - acc: 0.6103 - val_loss: 0.9800 - val_acc: 0.5830\n",
      "Epoch 38/50\n",
      "32000/32000 [==============================] - 22s 675us/step - loss: 0.9192 - acc: 0.6109 - val_loss: 0.9830 - val_acc: 0.5799\n",
      "Epoch 39/50\n",
      "32000/32000 [==============================] - 22s 678us/step - loss: 0.9147 - acc: 0.6097 - val_loss: 0.9814 - val_acc: 0.5791\n",
      "Epoch 40/50\n",
      "32000/32000 [==============================] - 22s 675us/step - loss: 0.9163 - acc: 0.6126 - val_loss: 0.9838 - val_acc: 0.5845\n",
      "Epoch 41/50\n",
      "32000/32000 [==============================] - 22s 673us/step - loss: 0.9151 - acc: 0.6137 - val_loss: 0.9816 - val_acc: 0.5850\n",
      "Epoch 42/50\n",
      "32000/32000 [==============================] - 22s 674us/step - loss: 0.9129 - acc: 0.6162 - val_loss: 0.9879 - val_acc: 0.5835\n",
      "Epoch 43/50\n",
      "32000/32000 [==============================] - 22s 676us/step - loss: 0.9154 - acc: 0.6118 - val_loss: 0.9806 - val_acc: 0.5796\n",
      "Epoch 44/50\n",
      "32000/32000 [==============================] - 22s 675us/step - loss: 0.9145 - acc: 0.6145 - val_loss: 0.9838 - val_acc: 0.5817\n",
      "Epoch 45/50\n",
      "32000/32000 [==============================] - 22s 678us/step - loss: 0.9136 - acc: 0.6123 - val_loss: 0.9859 - val_acc: 0.5841\n",
      "Epoch 46/50\n",
      "32000/32000 [==============================] - 22s 675us/step - loss: 0.9135 - acc: 0.6158 - val_loss: 0.9859 - val_acc: 0.5780\n",
      "Epoch 47/50\n",
      "32000/32000 [==============================] - 22s 673us/step - loss: 0.9114 - acc: 0.6147 - val_loss: 0.9962 - val_acc: 0.5773\n",
      "Epoch 48/50\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "32000/32000 [==============================] - 22s 675us/step - loss: 0.9109 - acc: 0.6162 - val_loss: 0.9852 - val_acc: 0.5817\n",
      "Epoch 49/50\n",
      "32000/32000 [==============================] - 22s 675us/step - loss: 0.9113 - acc: 0.6165 - val_loss: 0.9904 - val_acc: 0.5735\n",
      "Epoch 50/50\n",
      "32000/32000 [==============================] - 22s 678us/step - loss: 0.9124 - acc: 0.6163 - val_loss: 0.9873 - val_acc: 0.5805\n"
     ]
    }
   ],
   "source": [
    "model.summary()\n",
    "print(\"Training Progress:\")\n",
    "history = model.fit(x_train, y_train, validation_data=(x_val, y_val),\n",
    "                    epochs=50, batch_size=64,\n",
    "                    callbacks=[lr_schedule])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "pd.DataFrame(history.history).to_csv(\"history-4.csv\")\n",
    "#model.save('ltsm-c-3.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
