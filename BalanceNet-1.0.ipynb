{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## WideNet prototype"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[i] Loaded Parameters:\n",
      " 40000 35 0.2 200 \n",
      " dataset/glove/glove.twitter.27B.200d.txt\n",
      "[i] Importing Modules...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/h5py/__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n",
      "Using TensorFlow backend.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[+] Using Keras version 2.1.4\n",
      "[i] Finished Importing Modules\n",
      "[i] . Reading from csv file...Done!\n",
      "[i] Found 30505 unique tokens.\n",
      "[+] Shape of data tensor: (40000, 30)\n",
      "[+] Shape of label tensor: (40000, 6)\n",
      "[+] Number of entries in each category:\n",
      "[+] Training:\n",
      " [ 7662.  7448.  4789. 10948.  1068.    85.]\n",
      "[+] Validation:\n",
      " [1982. 1822. 1240. 2676.  255.   25.]\n",
      "[i] Loading GloVe from: dataset/glove/glove.twitter.27B.200d.txt ...Done.\n",
      "[+] Proceeding with Embedding Matrix...Completed!\n",
      "Finished running setup.\n"
     ]
    }
   ],
   "source": [
    "%run Setup.ipynb\n",
    "%run ExtraFunctions.ipynb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done.\n",
      "[+] Proceeding with Embedding Matrix...Completed!\n"
     ]
    }
   ],
   "source": [
    "# second embedding matrix for non-static channel\n",
    "'''embeddings_index = {}\n",
    "f = open(GLOVE_DIR)\n",
    "print(\"[i] Loading GloVe from:\",GLOVE_DIR,\"...\",end=\"\")\n",
    "for line in f:\n",
    "    values = line.split()\n",
    "    word = values[0]\n",
    "    embeddings_index[word] = np.asarray(values[1:], dtype='float32')\n",
    "f.close()'''\n",
    "print(\"Done.\\n[+] Proceeding with Embedding Matrix...\", end=\"\")\n",
    "embedding_matrix_ns = np.random.random((len(word_index) + 1, EMBEDDING_DIM))\n",
    "for word, i in word_index.items():\n",
    "    embedding_vector = embeddings_index.get(word)\n",
    "    if embedding_vector is not None:\n",
    "        # words not found in embedding index will be all-zeros.\n",
    "        embedding_matrix_ns[i] = embedding_vector\n",
    "print(\"Completed!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "sequence_input = Input(shape=(MAX_SEQUENCE_LENGTH,), dtype='int32')\n",
    "\n",
    "# static channel\n",
    "embedding_layer_frozen = Embedding(len(word_index) + 1,\n",
    "                            EMBEDDING_DIM,\n",
    "                            weights=[embedding_matrix],\n",
    "                            input_length=MAX_SEQUENCE_LENGTH,\n",
    "                            trainable=False)\n",
    "embedded_sequences_frozen = embedding_layer_frozen(sequence_input)\n",
    "\n",
    "# non-static channel\n",
    "embedding_layer_train = Embedding(len(word_index) + 1,\n",
    "                            EMBEDDING_DIM,\n",
    "                            weights=[embedding_matrix_ns],\n",
    "                            input_length=MAX_SEQUENCE_LENGTH,\n",
    "                            trainable=True)\n",
    "embedded_sequences_train = embedding_layer_train(sequence_input)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First Half: LSTM > CNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "l_lstm1f = Bidirectional(LSTM(6,return_sequences=True,dropout=0.15, recurrent_dropout=0.0))(embedded_sequences_frozen)\n",
    "l_lstm1t = Bidirectional(LSTM(6,return_sequences=True,dropout=0.15, recurrent_dropout=0.0))(embedded_sequences_train)\n",
    "l_lstm1 = Concatenate(axis=1)([l_lstm1f, l_lstm1t])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "l_conv_7 = Conv1D(filters=24,kernel_size=7,activation='relu',kernel_regularizer=regularizers.l2(0.001))(l_lstm1)\n",
    "l_conv_7 = Dropout(0.15)(l_conv_7)\n",
    "l_conv_6 = Conv1D(filters=24,kernel_size=6,activation='relu',kernel_regularizer=regularizers.l2(0.001))(l_lstm1)\n",
    "l_conv_6 = Dropout(0.15)(l_conv_6)\n",
    "\n",
    "l_conv_8 = Conv1D(filters=24,kernel_size=8,activation='relu',kernel_regularizer=regularizers.l2(0.001))(l_lstm1)\n",
    "l_conv_8 = Dropout(0.25)(l_conv_8)\n",
    "\n",
    "conv_1 = [l_conv_7, l_conv_6, l_conv_8]\n",
    "\n",
    "l_lstm_c = Concatenate(axis=1)(conv_1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Second Half: CNN > LSTM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "l_conv_4f = Conv1D(filters=12,kernel_size=4,activation='relu',kernel_regularizer=regularizers.l2(0.001))(embedded_sequences_frozen)\n",
    "l_conv_4f = Dropout(0.25)(l_conv_4f)\n",
    "l_conv_4t = Conv1D(filters=12,kernel_size=4,activation='relu',kernel_regularizer=regularizers.l2(0.001))(embedded_sequences_train)\n",
    "l_conv_4t = Dropout(0.25)(l_conv_4t)\n",
    "\n",
    "l_conv_3f = Conv1D(filters=12,kernel_size=3,activation='relu',kernel_regularizer=regularizers.l2(0.001))(embedded_sequences_frozen)\n",
    "l_conv_3f = Dropout(0.15)(l_conv_3f)\n",
    "l_conv_3t = Conv1D(filters=12,kernel_size=3,activation='relu',kernel_regularizer=regularizers.l2(0.001))(embedded_sequences_train)\n",
    "l_conv_3t = Dropout(0.15)(l_conv_3t)\n",
    "\n",
    "l_conv_2f = Conv1D(filters=12,kernel_size=2,activation='relu',kernel_regularizer=regularizers.l2(0.001))(embedded_sequences_frozen)\n",
    "l_conv_2f = Dropout(0.15)(l_conv_2f)\n",
    "l_conv_2t = Conv1D(filters=12,kernel_size=2,activation='relu',kernel_regularizer=regularizers.l2(0.001))(embedded_sequences_train)\n",
    "l_conv_2t = Dropout(0.15)(l_conv_2t)\n",
    "\n",
    "conv_2 = [l_conv_4f, l_conv_4t,l_conv_3f, l_conv_3t, l_conv_2f, l_conv_2t]\n",
    "\n",
    "l_merge_2 = Concatenate(axis=1)(conv_2)\n",
    "l_c_lstm = Bidirectional(LSTM(12,return_sequences=True,dropout=0.15, recurrent_dropout=0.0))(l_merge_2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Combine both halfs of the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "l_merge = Concatenate(axis=1)([l_lstm_c, l_c_lstm])\n",
    "l_pool = MaxPooling1D(4)(l_merge)\n",
    "l_drop = Dropout(0.5)(l_pool)\n",
    "l_flat = Flatten()(l_drop)\n",
    "l_dense = Dense(12, activation='relu')(l_flat)\n",
    "preds = Dense(6, activation='softmax')(l_dense)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Model(sequence_input, preds)\n",
    "adadelta = optimizers.Adadelta(lr=1.0, rho=0.95, epsilon=None, decay=0.0)\n",
    "lr_metric = get_lr_metric(adadelta)\n",
    "model.compile(loss='categorical_crossentropy',\n",
    "              optimizer=adadelta,\n",
    "              metrics=['acc'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "!rm -r logs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "tensorboard = callbacks.TensorBoard(log_dir='./logs', histogram_freq=0, batch_size=16, write_grads=True , write_graph=True)\n",
    "model_checkpoints = callbacks.ModelCheckpoint(\"checkpoint.h5\", monitor='val_loss', verbose=0, save_best_only=True, save_weights_only=False, mode='auto', period=1)\n",
    "lr_schedule = callbacks.LearningRateScheduler(initial_boost)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_1 (InputLayer)            (None, 30)           0                                            \n",
      "__________________________________________________________________________________________________\n",
      "embedding_1 (Embedding)         (None, 30, 200)      6101200     input_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "embedding_2 (Embedding)         (None, 30, 200)      6101200     input_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "bidirectional_1 (Bidirectional) (None, 30, 12)       9936        embedding_1[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "bidirectional_2 (Bidirectional) (None, 30, 12)       9936        embedding_2[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_1 (Concatenate)     (None, 60, 12)       0           bidirectional_1[0][0]            \n",
      "                                                                 bidirectional_2[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_4 (Conv1D)               (None, 27, 12)       9612        embedding_1[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_5 (Conv1D)               (None, 27, 12)       9612        embedding_2[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_6 (Conv1D)               (None, 28, 12)       7212        embedding_1[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_7 (Conv1D)               (None, 28, 12)       7212        embedding_2[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_8 (Conv1D)               (None, 29, 12)       4812        embedding_1[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_9 (Conv1D)               (None, 29, 12)       4812        embedding_2[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_1 (Conv1D)               (None, 54, 24)       2040        concatenate_1[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_2 (Conv1D)               (None, 55, 24)       1752        concatenate_1[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_3 (Conv1D)               (None, 53, 24)       2328        concatenate_1[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "dropout_4 (Dropout)             (None, 27, 12)       0           conv1d_4[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "dropout_5 (Dropout)             (None, 27, 12)       0           conv1d_5[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "dropout_6 (Dropout)             (None, 28, 12)       0           conv1d_6[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "dropout_7 (Dropout)             (None, 28, 12)       0           conv1d_7[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "dropout_8 (Dropout)             (None, 29, 12)       0           conv1d_8[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "dropout_9 (Dropout)             (None, 29, 12)       0           conv1d_9[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "dropout_1 (Dropout)             (None, 54, 24)       0           conv1d_1[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "dropout_2 (Dropout)             (None, 55, 24)       0           conv1d_2[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "dropout_3 (Dropout)             (None, 53, 24)       0           conv1d_3[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_3 (Concatenate)     (None, 168, 12)      0           dropout_4[0][0]                  \n",
      "                                                                 dropout_5[0][0]                  \n",
      "                                                                 dropout_6[0][0]                  \n",
      "                                                                 dropout_7[0][0]                  \n",
      "                                                                 dropout_8[0][0]                  \n",
      "                                                                 dropout_9[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_2 (Concatenate)     (None, 162, 24)      0           dropout_1[0][0]                  \n",
      "                                                                 dropout_2[0][0]                  \n",
      "                                                                 dropout_3[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "bidirectional_3 (Bidirectional) (None, 168, 24)      2400        concatenate_3[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_4 (Concatenate)     (None, 330, 24)      0           concatenate_2[0][0]              \n",
      "                                                                 bidirectional_3[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling1d_1 (MaxPooling1D)  (None, 82, 24)       0           concatenate_4[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "dropout_10 (Dropout)            (None, 82, 24)       0           max_pooling1d_1[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "flatten_1 (Flatten)             (None, 1968)         0           dropout_10[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "dense_1 (Dense)                 (None, 12)           23628       flatten_1[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dense_2 (Dense)                 (None, 6)            78          dense_1[0][0]                    \n",
      "==================================================================================================\n",
      "Total params: 12,297,770\n",
      "Trainable params: 6,196,570\n",
      "Non-trainable params: 6,101,200\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()\n",
    "model.save('BalanceNet.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Progress:\n",
      "Train on 32000 samples, validate on 8000 samples\n",
      "Epoch 1/200\n",
      "32000/32000 [==============================] - 202s 6ms/step - loss: 1.4720 - acc: 0.3828 - val_loss: 1.3505 - val_acc: 0.4481\n",
      "Epoch 2/200\n",
      "32000/32000 [==============================] - 199s 6ms/step - loss: 1.3109 - acc: 0.4703 - val_loss: 1.2990 - val_acc: 0.4675\n",
      "Epoch 3/200\n",
      "32000/32000 [==============================] - 198s 6ms/step - loss: 1.2753 - acc: 0.4848 - val_loss: 1.2726 - val_acc: 0.4815\n",
      "Epoch 4/200\n",
      "32000/32000 [==============================] - 199s 6ms/step - loss: 1.2540 - acc: 0.4985 - val_loss: 1.2582 - val_acc: 0.5001\n",
      "Epoch 5/200\n",
      "32000/32000 [==============================] - 199s 6ms/step - loss: 1.2328 - acc: 0.5099 - val_loss: 1.2592 - val_acc: 0.4900\n",
      "Epoch 6/200\n",
      "32000/32000 [==============================] - 194s 6ms/step - loss: 1.2197 - acc: 0.5187 - val_loss: 1.2465 - val_acc: 0.4981\n",
      "Epoch 7/200\n",
      "32000/32000 [==============================] - 187s 6ms/step - loss: 1.2076 - acc: 0.5245 - val_loss: 1.2351 - val_acc: 0.5046\n",
      "Epoch 8/200\n",
      "32000/32000 [==============================] - 186s 6ms/step - loss: 1.1952 - acc: 0.5308 - val_loss: 1.2381 - val_acc: 0.5075\n",
      "Epoch 9/200\n",
      "32000/32000 [==============================] - 186s 6ms/step - loss: 1.1839 - acc: 0.5389 - val_loss: 1.2420 - val_acc: 0.5044\n",
      "Epoch 10/200\n",
      "32000/32000 [==============================] - 187s 6ms/step - loss: 1.1740 - acc: 0.5419 - val_loss: 1.2413 - val_acc: 0.5087\n",
      "Epoch 11/200\n",
      "32000/32000 [==============================] - 187s 6ms/step - loss: 1.1632 - acc: 0.5494 - val_loss: 1.2416 - val_acc: 0.5080\n",
      "Epoch 12/200\n",
      "32000/32000 [==============================] - 186s 6ms/step - loss: 1.1578 - acc: 0.5532 - val_loss: 1.2513 - val_acc: 0.5026\n",
      "Epoch 13/200\n",
      "32000/32000 [==============================] - 186s 6ms/step - loss: 1.1482 - acc: 0.5562 - val_loss: 1.2725 - val_acc: 0.4945\n",
      "Epoch 14/200\n",
      "32000/32000 [==============================] - 186s 6ms/step - loss: 1.1395 - acc: 0.5619 - val_loss: 1.2546 - val_acc: 0.5074\n",
      "Epoch 15/200\n",
      "32000/32000 [==============================] - 186s 6ms/step - loss: 1.1340 - acc: 0.5648 - val_loss: 1.2674 - val_acc: 0.4960\n",
      "Epoch 16/200\n",
      "32000/32000 [==============================] - 186s 6ms/step - loss: 1.1226 - acc: 0.5715 - val_loss: 1.2855 - val_acc: 0.4940\n",
      "Epoch 17/200\n",
      "32000/32000 [==============================] - 186s 6ms/step - loss: 1.1158 - acc: 0.5744 - val_loss: 1.2792 - val_acc: 0.5019\n",
      "Epoch 18/200\n",
      "32000/32000 [==============================] - 186s 6ms/step - loss: 1.1003 - acc: 0.5822 - val_loss: 1.2985 - val_acc: 0.4896\n",
      "Epoch 19/200\n",
      "32000/32000 [==============================] - 186s 6ms/step - loss: 1.0920 - acc: 0.5876 - val_loss: 1.2899 - val_acc: 0.4901\n",
      "Epoch 20/200\n",
      "32000/32000 [==============================] - 186s 6ms/step - loss: 1.0850 - acc: 0.5921 - val_loss: 1.2834 - val_acc: 0.4945\n",
      "Epoch 21/200\n",
      "32000/32000 [==============================] - 186s 6ms/step - loss: 1.0751 - acc: 0.5984 - val_loss: 1.3051 - val_acc: 0.4977\n",
      "Epoch 22/200\n",
      "32000/32000 [==============================] - 187s 6ms/step - loss: 1.0604 - acc: 0.6026 - val_loss: 1.3249 - val_acc: 0.4929\n",
      "Epoch 23/200\n",
      "32000/32000 [==============================] - 186s 6ms/step - loss: 1.0533 - acc: 0.6100 - val_loss: 1.3400 - val_acc: 0.4896\n",
      "Epoch 24/200\n",
      "32000/32000 [==============================] - 186s 6ms/step - loss: 1.0425 - acc: 0.6131 - val_loss: 1.3351 - val_acc: 0.4848\n",
      "Epoch 25/200\n",
      "32000/32000 [==============================] - 186s 6ms/step - loss: 1.0337 - acc: 0.6186 - val_loss: 1.3728 - val_acc: 0.4879\n",
      "Epoch 26/200\n",
      "32000/32000 [==============================] - 186s 6ms/step - loss: 1.0200 - acc: 0.6233 - val_loss: 1.3649 - val_acc: 0.4857\n",
      "Epoch 27/200\n",
      "32000/32000 [==============================] - 186s 6ms/step - loss: 1.0110 - acc: 0.6317 - val_loss: 1.3713 - val_acc: 0.4825\n",
      "Epoch 28/200\n",
      "32000/32000 [==============================] - 186s 6ms/step - loss: 0.9999 - acc: 0.6351 - val_loss: 1.3816 - val_acc: 0.4891\n",
      "Epoch 29/200\n",
      "32000/32000 [==============================] - 185s 6ms/step - loss: 0.9874 - acc: 0.6410 - val_loss: 1.3807 - val_acc: 0.4874\n",
      "Epoch 30/200\n",
      "32000/32000 [==============================] - 187s 6ms/step - loss: 0.9740 - acc: 0.6467 - val_loss: 1.4227 - val_acc: 0.4814\n",
      "Epoch 31/200\n",
      "32000/32000 [==============================] - 187s 6ms/step - loss: 0.9643 - acc: 0.6534 - val_loss: 1.4894 - val_acc: 0.4881\n",
      "Epoch 32/200\n",
      "32000/32000 [==============================] - 186s 6ms/step - loss: 0.9520 - acc: 0.6574 - val_loss: 1.4180 - val_acc: 0.4810\n",
      "Epoch 33/200\n",
      "32000/32000 [==============================] - 186s 6ms/step - loss: 0.9387 - acc: 0.6611 - val_loss: 1.4578 - val_acc: 0.4807\n",
      "Epoch 34/200\n",
      "32000/32000 [==============================] - 186s 6ms/step - loss: 0.9297 - acc: 0.6670 - val_loss: 1.4648 - val_acc: 0.4701\n",
      "Epoch 35/200\n",
      "32000/32000 [==============================] - 186s 6ms/step - loss: 0.9194 - acc: 0.6733 - val_loss: 1.4909 - val_acc: 0.4689\n",
      "Epoch 36/200\n",
      "32000/32000 [==============================] - 186s 6ms/step - loss: 0.9105 - acc: 0.6766 - val_loss: 1.4917 - val_acc: 0.4570\n",
      "Epoch 37/200\n",
      "32000/32000 [==============================] - 186s 6ms/step - loss: 0.8947 - acc: 0.6840 - val_loss: 1.5059 - val_acc: 0.4600\n",
      "Epoch 38/200\n",
      "32000/32000 [==============================] - 186s 6ms/step - loss: 0.8876 - acc: 0.6880 - val_loss: 1.5285 - val_acc: 0.4692\n",
      "Epoch 39/200\n",
      "32000/32000 [==============================] - 186s 6ms/step - loss: 0.8742 - acc: 0.6925 - val_loss: 1.5679 - val_acc: 0.4620\n",
      "Epoch 40/200\n",
      "32000/32000 [==============================] - 186s 6ms/step - loss: 0.8655 - acc: 0.6954 - val_loss: 1.5550 - val_acc: 0.4710\n",
      "Epoch 41/200\n",
      "32000/32000 [==============================] - 186s 6ms/step - loss: 0.8612 - acc: 0.7000 - val_loss: 1.5661 - val_acc: 0.4706\n",
      "Epoch 42/200\n",
      "32000/32000 [==============================] - 186s 6ms/step - loss: 0.8487 - acc: 0.7047 - val_loss: 1.6393 - val_acc: 0.4670\n",
      "Epoch 43/200\n",
      "32000/32000 [==============================] - 187s 6ms/step - loss: 0.8287 - acc: 0.7128 - val_loss: 1.6338 - val_acc: 0.4639\n",
      "Epoch 44/200\n",
      "32000/32000 [==============================] - 187s 6ms/step - loss: 0.8222 - acc: 0.7147 - val_loss: 1.6874 - val_acc: 0.4615\n",
      "Epoch 45/200\n",
      "32000/32000 [==============================] - 187s 6ms/step - loss: 0.8108 - acc: 0.7204 - val_loss: 1.6944 - val_acc: 0.4550\n",
      "Epoch 46/200\n",
      "32000/32000 [==============================] - 186s 6ms/step - loss: 0.8065 - acc: 0.7207 - val_loss: 1.6842 - val_acc: 0.4544\n",
      "Epoch 47/200\n",
      "32000/32000 [==============================] - 187s 6ms/step - loss: 0.7947 - acc: 0.7240 - val_loss: 1.6990 - val_acc: 0.4636\n",
      "Epoch 48/200\n",
      "32000/32000 [==============================] - 186s 6ms/step - loss: 0.7868 - acc: 0.7298 - val_loss: 1.7408 - val_acc: 0.4551\n",
      "Epoch 49/200\n",
      "32000/32000 [==============================] - 186s 6ms/step - loss: 0.7766 - acc: 0.7337 - val_loss: 1.7460 - val_acc: 0.4532\n",
      "Epoch 50/200\n",
      "32000/32000 [==============================] - 186s 6ms/step - loss: 0.7637 - acc: 0.7399 - val_loss: 1.8059 - val_acc: 0.4431\n",
      "Epoch 51/200\n",
      "32000/32000 [==============================] - 186s 6ms/step - loss: 0.7529 - acc: 0.7443 - val_loss: 1.8528 - val_acc: 0.4512\n",
      "Epoch 52/200\n",
      "32000/32000 [==============================] - 186s 6ms/step - loss: 0.7489 - acc: 0.7487 - val_loss: 1.8071 - val_acc: 0.4504\n",
      "Epoch 53/200\n",
      "32000/32000 [==============================] - 186s 6ms/step - loss: 0.7391 - acc: 0.7502 - val_loss: 1.8346 - val_acc: 0.4555\n",
      "Epoch 54/200\n",
      "32000/32000 [==============================] - 186s 6ms/step - loss: 0.7301 - acc: 0.7534 - val_loss: 1.8548 - val_acc: 0.4580\n",
      "Epoch 55/200\n",
      "32000/32000 [==============================] - 186s 6ms/step - loss: 0.7214 - acc: 0.7570 - val_loss: 1.8991 - val_acc: 0.4525\n",
      "Epoch 56/200\n",
      "32000/32000 [==============================] - 175s 5ms/step - loss: 0.7125 - acc: 0.7612 - val_loss: 1.8896 - val_acc: 0.4506\n",
      "Epoch 57/200\n",
      "32000/32000 [==============================] - 185s 6ms/step - loss: 0.7074 - acc: 0.7631 - val_loss: 1.9700 - val_acc: 0.4455\n",
      "Epoch 58/200\n",
      "32000/32000 [==============================] - 186s 6ms/step - loss: 0.6975 - acc: 0.7682 - val_loss: 1.9572 - val_acc: 0.4432\n",
      "Epoch 59/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "32000/32000 [==============================] - 186s 6ms/step - loss: 0.6904 - acc: 0.7728 - val_loss: 1.8712 - val_acc: 0.4430\n",
      "Epoch 60/200\n",
      "32000/32000 [==============================] - 186s 6ms/step - loss: 0.6823 - acc: 0.7742 - val_loss: 1.9591 - val_acc: 0.4467\n",
      "Epoch 61/200\n",
      "32000/32000 [==============================] - 186s 6ms/step - loss: 0.6681 - acc: 0.7792 - val_loss: 2.1107 - val_acc: 0.4412\n",
      "Epoch 62/200\n",
      "32000/32000 [==============================] - 186s 6ms/step - loss: 0.6664 - acc: 0.7795 - val_loss: 2.0308 - val_acc: 0.4405\n",
      "Epoch 63/200\n",
      "32000/32000 [==============================] - 186s 6ms/step - loss: 0.6630 - acc: 0.7806 - val_loss: 2.0347 - val_acc: 0.4432\n",
      "Epoch 64/200\n",
      "32000/32000 [==============================] - 186s 6ms/step - loss: 0.6552 - acc: 0.7857 - val_loss: 2.1309 - val_acc: 0.4434\n",
      "Epoch 65/200\n",
      "32000/32000 [==============================] - 187s 6ms/step - loss: 0.6467 - acc: 0.7880 - val_loss: 2.0070 - val_acc: 0.4310\n",
      "Epoch 66/200\n",
      "32000/32000 [==============================] - 187s 6ms/step - loss: 0.6446 - acc: 0.7867 - val_loss: 2.0211 - val_acc: 0.4372\n",
      "Epoch 67/200\n",
      "32000/32000 [==============================] - 187s 6ms/step - loss: 0.6356 - acc: 0.7913 - val_loss: 2.1705 - val_acc: 0.4390\n",
      "Epoch 68/200\n",
      "32000/32000 [==============================] - 186s 6ms/step - loss: 0.6320 - acc: 0.7944 - val_loss: 2.0944 - val_acc: 0.4420\n",
      "Epoch 69/200\n",
      "32000/32000 [==============================] - 186s 6ms/step - loss: 0.6205 - acc: 0.7984 - val_loss: 2.0604 - val_acc: 0.4452\n",
      "Epoch 70/200\n",
      "32000/32000 [==============================] - 186s 6ms/step - loss: 0.6245 - acc: 0.7974 - val_loss: 2.0867 - val_acc: 0.4413\n",
      "Epoch 71/200\n",
      "32000/32000 [==============================] - 186s 6ms/step - loss: 0.6085 - acc: 0.8015 - val_loss: 2.1803 - val_acc: 0.4350\n",
      "Epoch 72/200\n",
      "32000/32000 [==============================] - 187s 6ms/step - loss: 0.6050 - acc: 0.8026 - val_loss: 2.1643 - val_acc: 0.4460\n",
      "Epoch 73/200\n",
      "32000/32000 [==============================] - 187s 6ms/step - loss: 0.6051 - acc: 0.8036 - val_loss: 2.2227 - val_acc: 0.4417\n",
      "Epoch 74/200\n",
      "32000/32000 [==============================] - 186s 6ms/step - loss: 0.5957 - acc: 0.8078 - val_loss: 2.2501 - val_acc: 0.4374\n",
      "Epoch 75/200\n",
      "32000/32000 [==============================] - 187s 6ms/step - loss: 0.5937 - acc: 0.8079 - val_loss: 2.2571 - val_acc: 0.4356\n",
      "Epoch 76/200\n",
      "32000/32000 [==============================] - 187s 6ms/step - loss: 0.5871 - acc: 0.8114 - val_loss: 2.2328 - val_acc: 0.4311\n",
      "Epoch 77/200\n",
      "32000/32000 [==============================] - 187s 6ms/step - loss: 0.5781 - acc: 0.8161 - val_loss: 2.2797 - val_acc: 0.4375\n",
      "Epoch 78/200\n",
      "32000/32000 [==============================] - 186s 6ms/step - loss: 0.5752 - acc: 0.8167 - val_loss: 2.2832 - val_acc: 0.4342\n",
      "Epoch 79/200\n",
      "32000/32000 [==============================] - 186s 6ms/step - loss: 0.5701 - acc: 0.8182 - val_loss: 2.3020 - val_acc: 0.4367\n",
      "Epoch 80/200\n",
      "32000/32000 [==============================] - 186s 6ms/step - loss: 0.5608 - acc: 0.8197 - val_loss: 2.3918 - val_acc: 0.4317\n",
      "Epoch 81/200\n",
      "32000/32000 [==============================] - 186s 6ms/step - loss: 0.5598 - acc: 0.8222 - val_loss: 2.3598 - val_acc: 0.4385\n",
      "Epoch 82/200\n",
      "32000/32000 [==============================] - 186s 6ms/step - loss: 0.5501 - acc: 0.8256 - val_loss: 2.5160 - val_acc: 0.4305\n",
      "Epoch 83/200\n",
      "32000/32000 [==============================] - 186s 6ms/step - loss: 0.5505 - acc: 0.8263 - val_loss: 2.4525 - val_acc: 0.4339\n",
      "Epoch 84/200\n",
      "32000/32000 [==============================] - 187s 6ms/step - loss: 0.5471 - acc: 0.8259 - val_loss: 2.3473 - val_acc: 0.4377\n",
      "Epoch 85/200\n",
      "32000/32000 [==============================] - 187s 6ms/step - loss: 0.5383 - acc: 0.8295 - val_loss: 2.4495 - val_acc: 0.4384\n",
      "Epoch 86/200\n",
      "32000/32000 [==============================] - 187s 6ms/step - loss: 0.5364 - acc: 0.8318 - val_loss: 2.3704 - val_acc: 0.4290\n",
      "Epoch 87/200\n",
      "32000/32000 [==============================] - 187s 6ms/step - loss: 0.5333 - acc: 0.8315 - val_loss: 2.4771 - val_acc: 0.4356\n",
      "Epoch 88/200\n",
      "32000/32000 [==============================] - 187s 6ms/step - loss: 0.5301 - acc: 0.8332 - val_loss: 2.4276 - val_acc: 0.4325\n",
      "Epoch 89/200\n",
      "32000/32000 [==============================] - 186s 6ms/step - loss: 0.5290 - acc: 0.8345 - val_loss: 2.3985 - val_acc: 0.4310\n",
      "Epoch 90/200\n",
      "32000/32000 [==============================] - 186s 6ms/step - loss: 0.5223 - acc: 0.8350 - val_loss: 2.5139 - val_acc: 0.4319\n",
      "Epoch 91/200\n",
      "32000/32000 [==============================] - 186s 6ms/step - loss: 0.5182 - acc: 0.8377 - val_loss: 2.5344 - val_acc: 0.4265\n",
      "Epoch 92/200\n",
      "32000/32000 [==============================] - 186s 6ms/step - loss: 0.5128 - acc: 0.8401 - val_loss: 2.5704 - val_acc: 0.4262\n",
      "Epoch 93/200\n",
      "32000/32000 [==============================] - 186s 6ms/step - loss: 0.5090 - acc: 0.8390 - val_loss: 2.5951 - val_acc: 0.4287\n",
      "Epoch 94/200\n",
      "32000/32000 [==============================] - 186s 6ms/step - loss: 0.5066 - acc: 0.8408 - val_loss: 2.4238 - val_acc: 0.4350\n",
      "Epoch 95/200\n",
      "32000/32000 [==============================] - 186s 6ms/step - loss: 0.5051 - acc: 0.8423 - val_loss: 2.5566 - val_acc: 0.4236\n",
      "Epoch 96/200\n",
      "32000/32000 [==============================] - 186s 6ms/step - loss: 0.5044 - acc: 0.8415 - val_loss: 2.5066 - val_acc: 0.4285\n",
      "Epoch 97/200\n",
      "32000/32000 [==============================] - 186s 6ms/step - loss: 0.4942 - acc: 0.8457 - val_loss: 2.5871 - val_acc: 0.4281\n",
      "Epoch 98/200\n",
      "32000/32000 [==============================] - 186s 6ms/step - loss: 0.4910 - acc: 0.8463 - val_loss: 2.6831 - val_acc: 0.4377\n",
      "Epoch 99/200\n",
      "32000/32000 [==============================] - 186s 6ms/step - loss: 0.4901 - acc: 0.8487 - val_loss: 2.6412 - val_acc: 0.4360\n",
      "Epoch 100/200\n",
      "32000/32000 [==============================] - 185s 6ms/step - loss: 0.4929 - acc: 0.8475 - val_loss: 2.6216 - val_acc: 0.4292\n",
      "Epoch 101/200\n",
      "32000/32000 [==============================] - 186s 6ms/step - loss: 0.4873 - acc: 0.8505 - val_loss: 2.7289 - val_acc: 0.4272\n",
      "Epoch 102/200\n",
      "32000/32000 [==============================] - 186s 6ms/step - loss: 0.4783 - acc: 0.8502 - val_loss: 2.7964 - val_acc: 0.4400\n",
      "Epoch 103/200\n",
      "32000/32000 [==============================] - 186s 6ms/step - loss: 0.4806 - acc: 0.8511 - val_loss: 2.5988 - val_acc: 0.4300\n",
      "Epoch 104/200\n",
      "32000/32000 [==============================] - 186s 6ms/step - loss: 0.4757 - acc: 0.8517 - val_loss: 2.8084 - val_acc: 0.4369\n",
      "Epoch 105/200\n",
      " 6150/32000 [====>.........................] - ETA: 2:29 - loss: 0.4704 - acc: 0.8563"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-12-f83714b063df>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      2\u001b[0m model_log = model.fit(x_train, y_train, validation_data=(x_val, y_val),\n\u001b[1;32m      3\u001b[0m           \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m200\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m50\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m           callbacks=[tensorboard, lr_schedule])\n\u001b[0m",
      "\u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, **kwargs)\u001b[0m\n\u001b[1;32m   1710\u001b[0m                               \u001b[0minitial_epoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minitial_epoch\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1711\u001b[0m                               \u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1712\u001b[0;31m                               validation_steps=validation_steps)\n\u001b[0m\u001b[1;32m   1713\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1714\u001b[0m     def evaluate(self, x=None, y=None,\n",
      "\u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/keras/engine/training.py\u001b[0m in \u001b[0;36m_fit_loop\u001b[0;34m(self, f, ins, out_labels, batch_size, epochs, verbose, callbacks, val_f, val_ins, shuffle, callback_metrics, initial_epoch, steps_per_epoch, validation_steps)\u001b[0m\n\u001b[1;32m   1233\u001b[0m                         \u001b[0mins_batch\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mins_batch\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtoarray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1234\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1235\u001b[0;31m                     \u001b[0mouts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mins_batch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1236\u001b[0m                     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mouts\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1237\u001b[0m                         \u001b[0mouts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mouts\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m   2473\u001b[0m         \u001b[0msession\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_session\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2474\u001b[0m         updated = session.run(fetches=fetches, feed_dict=feed_dict,\n\u001b[0;32m-> 2475\u001b[0;31m                               **self.session_kwargs)\n\u001b[0m\u001b[1;32m   2476\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mupdated\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2477\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m    893\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    894\u001b[0m       result = self._run(None, fetches, feed_dict, options_ptr,\n\u001b[0;32m--> 895\u001b[0;31m                          run_metadata_ptr)\n\u001b[0m\u001b[1;32m    896\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    897\u001b[0m         \u001b[0mproto_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_run\u001b[0;34m(self, handle, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1126\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mfinal_fetches\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mfinal_targets\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mhandle\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mfeed_dict_tensor\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1127\u001b[0m       results = self._do_run(handle, final_targets, final_fetches,\n\u001b[0;32m-> 1128\u001b[0;31m                              feed_dict_tensor, options, run_metadata)\n\u001b[0m\u001b[1;32m   1129\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1130\u001b[0m       \u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_run\u001b[0;34m(self, handle, target_list, fetch_list, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1342\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mhandle\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1343\u001b[0m       return self._do_call(_run_fn, self._session, feeds, fetches, targets,\n\u001b[0;32m-> 1344\u001b[0;31m                            options, run_metadata)\n\u001b[0m\u001b[1;32m   1345\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1346\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_do_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_prun_fn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_session\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeeds\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetches\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_call\u001b[0;34m(self, fn, *args)\u001b[0m\n\u001b[1;32m   1348\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_do_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1349\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1350\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1351\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mOpError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1352\u001b[0m       \u001b[0mmessage\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcompat\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mas_text\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmessage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_run_fn\u001b[0;34m(session, feed_dict, fetch_list, target_list, options, run_metadata)\u001b[0m\n\u001b[1;32m   1327\u001b[0m           return tf_session.TF_Run(session, options,\n\u001b[1;32m   1328\u001b[0m                                    \u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget_list\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1329\u001b[0;31m                                    status, run_metadata)\n\u001b[0m\u001b[1;32m   1330\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1331\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_prun_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msession\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "print(\"Training Progress:\")\n",
    "model_log = model.fit(x_train, y_train, validation_data=(x_val, y_val),\n",
    "          epochs=200, batch_size=50,\n",
    "          callbacks=[tensorboard, lr_schedule])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "model.save('BalanceNet.h5')\n",
    "pd.DataFrame(model_log.history).to_csv(\"history-balance.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
